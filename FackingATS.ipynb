{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using Ollama**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def query_ollama_stream(keywords):\n",
    "    \"\"\"Interact with the Ollama server using streaming HTTP responses and overwrite output.\"\"\"\n",
    "    url = \"http://localhost:11434/api/chat\"  # Correct endpoint\n",
    "    prompt = f\"\"\"\n",
    "    Here is a list of keywords extracted from a job description:\n",
    "    {', '.join(keywords)}\n",
    "\n",
    "    Please return an array of keywords that represent professional skills or \n",
    "    technologies suitable for inclusion in a resume without any explanation and additonal text.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": \"llama3.1\",  # Replace with your desired model name\n",
    "        \"messages\": [  # Correct key\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Set stream=True to handle streamed responses\n",
    "        with requests.post(url, json=payload, headers=headers, stream=True) as response:\n",
    "            response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "\n",
    "            full_response = \"\"  # Initialize a variable to store the complete response\n",
    "            for line in response.iter_lines():\n",
    "                if line:  # Skip empty lines\n",
    "                    try:\n",
    "                        # Decode the JSON line\n",
    "                        json_line = json.loads(line.decode(\"utf-8\"))\n",
    "                        # Extract the assistant's content\n",
    "                        content = json_line.get(\"message\", {}).get(\"content\", \"\")\n",
    "                        if content:\n",
    "                            full_response += content  # Append new content\n",
    "                            # # Overwrite the line with the updated response\n",
    "                            # sys.stdout.write(f\"\\r{full_response}\")\n",
    "                            # sys.stdout.flush()\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON line: {e}\")\n",
    "\n",
    "            print()  # Move to a new line after the response is complete\n",
    "            return full_response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Error querying Ollama: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extracting keywords with NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def process_job_description(file_path):\n",
    "    # Step 1: Read the contents of the offer.txt file\n",
    "    with open(file_path, 'r') as file:\n",
    "        job_description = file.read()\n",
    "    \n",
    "    doc = nlp(job_description)\n",
    "    keywords = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return set(keywords)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using Openai APIs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import ast \n",
    "\n",
    "\n",
    "def query_openai_for_keywords(keywords):\n",
    "    \"\"\"\n",
    "    Query OpenAI's API to identify professional keywords using the updated method.\n",
    "    \"\"\"\n",
    "    # Load API key from environment variable\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        raise Exception(\"OPENAI_API_KEY is not set in the environment variables.\")\n",
    "    \n",
    "    # Initialize OpenAI client with the API key\n",
    "    client = openai.Client(api_key=openai_api_key)\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = f\"\"\"\n",
    "    Filter the following text for professional skills, technologies, or competencies:\n",
    "    {', '.join(keywords)}.\n",
    "    Just Return the result as a plain Python list of strings.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Call OpenAI API using client.chat.completions.create\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        # Extract the response content\n",
    "        # print(\"Raw Response Content:\", response)\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        # Safely evaluate the returned Python list\n",
    "        professional_keywords = ast.literal_eval(content)\n",
    "        return professional_keywords\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error querying OpenAI: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Professional Keywords for Resume:\n",
      "['Computer Science', 'Computer Engineering', 'Mathematics', 'Physics', 'Python', 'C#', 'Java', 'SQL', 'Italian', 'English', 'SW Developer', 'Problem Solving', 'Analytical Skills', 'Effective Communication', 'Microsoft Azure Ecosystem', 'REST and SOAP APIs', 'Code Communication (Message Broker)', 'Microservices Architecture Principles', 'Salesforce and APEX', 'Visualforce']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    job_description_file = \"offer.txt\"  # Path to your job description file\n",
    "\n",
    "    with open(job_description_file, 'r') as file:\n",
    "        job_description = file.read()\n",
    "    \n",
    "\n",
    "    professional_keywords = query_openai_for_keywords(job_description)\n",
    "    print(\"\\nProfessional Keywords for Resume:\")\n",
    "    print(professional_keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
